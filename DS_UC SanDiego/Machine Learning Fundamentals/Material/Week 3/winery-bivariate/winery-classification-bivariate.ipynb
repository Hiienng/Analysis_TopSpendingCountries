{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification with the bivariate Gaussian\n",
    "\n",
    "Our first generative model for Winery classification used just one feature. Now we use two features, modeling each class by a **bivariate Gaussian**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the univariate case, we start by loading in the Wine data set. Make sure the file `wine.data.txt` is in the same directory as this notebook.\n",
    "\n",
    "Recall that there are 178 data points, each with 13 features and a label (1,2,3). As before, we will divide this into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal \n",
    "# installing packages for interactive graphs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set.\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n",
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at the distribution of two features from one of the wineries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to plot the distribution of two features from a particular winery. We will use several helper functions for this. It is worth understanding each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first helper function fits a Gaussian to a data set, restricting attention to specified features.\n",
    "It returns the mean and covariance matrix of the Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Gaussian to a data set using the selected features\n",
    "def fit_gaussian(x, features):\n",
    "    mu = np.mean(x[:,features], axis=0)\n",
    "    covar = np.cov(x[:,features], rowvar=0, bias=1)\n",
    "    return mu, covar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's look at the Gaussian we get for winery 1, using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "[13.78534884  2.99627907]\n",
      "Covariance matrix:\n",
      "[[0.23325279 0.07526874]\n",
      " [0.07526874 0.15240941]]\n"
     ]
    }
   ],
   "source": [
    "f1 = 0\n",
    "f2 = 6\n",
    "label = 1\n",
    "mu, covar = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "print(\"Mean:\\n\" + str(mu))\n",
    "print(\"Covariance matrix:\\n\" + str(covar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will construct a routine for displaying points sampled from a two-dimensional Gaussian, as well as a few contour lines. Part of doing this involves deciding what range to use for each axis. We begin with a little helper function that takes as input an array of numbers (values along a single feature) and returns the range in which these numbers lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the range within which an array of numbers lie, with a little buffer\n",
    "def find_range(x):\n",
    "    lower = min(x)\n",
    "    upper = max(x)\n",
    "    width = upper - lower\n",
    "    lower = lower - 0.2 * width\n",
    "    upper = upper + 0.2 * width\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a routine that plots a few contour lines of a given two-dimensional Gaussian.\n",
    "It takes as input:\n",
    "* `mu`, `cov`: the parameters of the Gaussian\n",
    "* `x1g`, `x2g`: the grid (along the two axes) at which the density is to be computed\n",
    "* `col`: the color of the contour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(mu, cov, x1g, x2g, col):\n",
    "    rv = multivariate_normal(mean=mu, cov=cov)\n",
    "    z = np.zeros((len(x1g),len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            z[j,i] = rv.logpdf([x1g[i], x2g[j]]) \n",
    "    sign, logdet = np.linalg.slogdet(cov)\n",
    "    normalizer = -0.5 * (2 * np.log(6.28) + sign * logdet)\n",
    "    for offset in range(1,4):\n",
    "        plt.contour(x1g,x2g,z, levels=[normalizer - offset], colors=col, linewidths=2.0, linestyles='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **two_features_plot** takes an input two features and a label, and displays the distribution for the specified winery and pair of features.\n",
    "\n",
    "The first line allows you to specify the parameters interactively using sliders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb68a6a235143a6bf915e794d5191e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1), label=IntSlider(1,1,3,1) )\n",
    "def two_features_plot(f1,f2,label):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[trainy==label,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[trainy==label,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    plt.plot(trainx[trainy==label, f1], trainx[trainy==label, f2], 'ro')\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Now plot a few contour lines of the density\n",
    "    mu, cov = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "    plot_contours(mu, cov, x1g, x2g, 'k')\n",
    "    \n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Class ' + str(label), fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Gaussian to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that will fit a Gaussian generative model to the three classes, restricted to a given list of features. The function returns:\n",
    "* `mu`: the means of the Gaussians, one per row\n",
    "* `covar`: covariance matrices of each of the Gaussians\n",
    "* `pi`: list of three class weights summing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "def fit_generative_model(x, y, features):\n",
    "    k = 3 # number of classes\n",
    "    d = len(features) # number of features\n",
    "    mu = np.zeros((k+1,d)) # list of means\n",
    "    covar = np.zeros((k+1,d,d)) # list of covariance matrices\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label,:], covar[label,:,:] = fit_gaussian(x[indices,:], features)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, covar, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the three Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8824311bc04c0c962a952845671d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def three_class_plot(f1,f2):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Show the Gaussian fit to each class, using features f1,f2\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    for label in range(1,4):\n",
    "        gmean = mu[label,:]\n",
    "        gcov = covar[label,:,:]\n",
    "        plot_contours(gmean, gcov, x1g, x2g, colors[label-1])\n",
    "\n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Wine data', fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict labels for the test points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we can predict the class (1,2,3) based just on these two features?\n",
    "\n",
    "We start with a testing procedure that is analogous to what we developed in the 1-d case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f40f8662b846b9bb6a1932d6a34873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "@interact( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def test_model(f1, f2):\n",
    "    if f1 == f2: # need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    features= [f1,f2]\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, features)\n",
    "    \n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    nt = len(testy) # Number of test points\n",
    "    score = np.zeros((nt,k+1))\n",
    "    for i in range(0,nt):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            multivariate_normal.logpdf(testx[i,features], mean=mu[label,:], cov=covar[label,:,:])\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    print(\"Test error using feature(s): \")\n",
    "    for f in features:\n",
    "        print(\"'\" + featurenames[f] + \"'\" + \" \",)\n",
    "    print()\n",
    "    print(\"Errors: \" + str(errors) + \"/\" + str(nt))# Now test the performance of a predictor based on a subset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different pairs of features yield different test errors.\n",
    "* What is the smallest achievable test error?\n",
    "* Which pair of features achieves this minimum test error?\n",
    "\n",
    "*Make a note of your answers to these questions, as you will need to enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. The decision boundary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **show_decision_boundary** takes as input two features, builds a classifier based only on these two features, and shows a plot that contains both the training data and the decision boundary.\n",
    "\n",
    "To compute the decision boundary, a dense grid is defined on the two-dimensional input space and the classifier is applied to every grid point. The built-in `pyplot.contour` function can then be invoked to depict the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_decision_boundary(f1,f2):\n",
    "    # Fit Gaussian to each class\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    \n",
    "    # Set up dimensions of plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "\n",
    "    # Plot points in training set\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a dense grid; every point in the grid will be classified according to the generative model\n",
    "    res = 200\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Declare random variables corresponding to each class density\n",
    "    random_vars = {}\n",
    "    for label in range(1,4):\n",
    "        random_vars[label] = multivariate_normal(mean=mu[label,:],cov=covar[label,:,:])\n",
    "\n",
    "    # Classify every point in the grid; these are stored in an array Z[]\n",
    "    Z = np.zeros((len(x1g), len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            scores = []\n",
    "            for label in range(1,4):\n",
    "                scores.append(np.log(pi[label]) + random_vars[label].logpdf([x1g[i],x2g[j]]))\n",
    "            Z[i,j] = np.argmax(scores) + 1\n",
    "\n",
    "    # Plot the contour lines\n",
    "    plt.contour(x1g,x2g,Z.T,3,cmap='seismic')\n",
    "    \n",
    "    # Finally, show the image\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function above to draw the decision boundary using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_decision_boundary(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you add interactive sliders to function **show_decision_boundary**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a plot similar to that of **show_decision_boundary**, but in which just the **test** data is shown.\n",
    "Look back at your answer to *Fast exercise 1*. Is it corroborated by your plot? Are the errors clearly visible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10d8e72d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1945878552.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    cons = {'type': 'eq', 'fun': lambda p: p[0] - (r + (mu_M - r) / sigma_M * p[1])} In [82]: opt = minimize(lambda p: -U(p), (0.1, 0.3), constraints=cons)\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def U(p):\n",
    "    mu, sigma = p\n",
    "    return mu-1/2*(sigma**2+mu**2) \n",
    "\n",
    "cons = {'type': 'eq', 'fun': lambda p: p[0] - (r + (mu_M - r) / sigma_M * p[1])} In [82]: opt = minimize(lambda p: -U(p), (0.1, 0.3), constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
