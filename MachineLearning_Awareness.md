# MACHINE LEARNING
## 1. Sự khác nhau của 3 mô hình phổ biến nhất
  - Linear Regression giả định mối quan hệ tuyến tính giữa các biến đầu vào và biến đầu ra, và cố gắng tìm đường thẳng phù hợp nhất để giảm thiểu sai số giữa các giá trị dự đoán và giá trị thực tế.
  - Decision Tree Regressor, sử dụng một cấu trúc cây để chia không gian đầu vào thành các khu vực nhỏ hơn, và dự đoán biến đầu ra dựa trên giá trị trung bình của các dữ liệu huấn luyện trong khu vực đó.
  - Random Forest là một thuật toán học tập kết hợp (ensemble learning), kết hợp nhiều cây quyết định để cải thiện độ chính xác dự đoán. Nó tạo ra một rừng các cây quyết định, trong đó mỗi cây được xây dựng trên một tập con ngẫu nhiên của dữ liệu huấn luyện và một tập con ngẫu nhiên của các đặc trưng đầu vào
## 2. MSE Train và R2 là hai thước đo đánh giá độ chính xác của mô hình trong bài toán hồi quy.
  - MSE Train (Mean Squared Error Train) là độ đo lỗi bình phương trung bình trên tập huấn luyện bằng tổng bình phương sai số trên tập huấn luyện và chia cho số mẫu trong tập huấn luyện. Giá trị MSE Train càng thấp thì mô hình càng tốt, tức là dự đoán của mô hình càng gần với giá trị thực tế trên tập huấn luyện.
  - R2 là hệ số xác định (coefficient of determination), cũng là một thước đo đánh giá độ chính xác của mô hình hồi quy. R2 được tính bằng tỉ lệ giữa sai số giải thích và tổng sai số trung bình trên tập huấn luyện. R2 có giá trị từ 0 đến 1, với giá trị càng gần 1 thì mô hình càng tốt, tức là mô hình giải thích được một phần lớn sự biến động của giá trị đầu ra trên tập huấn luyện. R2 = 1 nghĩa là mô hình hoàn toàn chính xác, trong khi R2 = 0 nghĩa là mô hình không tốt và dự đoán của nó tương đương với dự đoán ngẫu nhiên. 
## 3. Overfitting 
  - là khi mô hình đã học được quá nhiều từ dữ liệu huấn luyện, đến mức nó đã bao quát được cả những sự biến động ngẫu nhiên trong dữ liệu huấn luyện. Khi đó, mô hình có thể hoạt động rất tốt trên tập huấn luyện nhưng lại không hiệu quả trên dữ liệu mới, như tập kiểm tra hoặc tập dữ liệu thực tế.
  - Khi mô hình quá khớp, nó có xu hướng "ghi nhớ" dữ liệu huấn luyện, thay vì học cách tổng quát hóa vấn đề. Điều này dẫn đến các tham số mô hình được điều chỉnh quá chặt chẽ, dẫn đến khả năng dự đoán sai trên dữ liệu mới.
  - Để khắc phục vấn đề này, các biện pháp như giảm thiểu số lượng đặc trưng, tăng số lượng dữ liệu huấn luyện, sử dụng kỹ thuật regularization, hoặc sử dụng các thuật toán học máy khác như các mô hình ensemble (tập hợp).
  - Random Forest có khả năng giảm tỷ lệ overfitting hơn so với các mô hình hồi quy khác. Điều này bởi vì Random Forest là một phương pháp tập hợp nhiều cây quyết định (decision trees) độc lập nhau để tạo ra một mô hình dự đoán. Mỗi cây quyết định được xây dựng trên một tập con ngẫu nhiên của dữ liệu huấn luyện, và chỉ sử dụng một số đặc trưng ngẫu nhiên để xây dựng cây. Sau đó, mô hình sử dụng trung bình hoặc phiếu bầu của các cây quyết định để đưa ra dự đoán cuối cùng. Việc tạo ra nhiều cây quyết định độc lập nhau trên các tập con ngẫu nhiên của dữ liệu huấn luyện, và sử dụng một số đặc trưng ngẫu nhiên để xây dựng các cây này, giúp giảm thiểu tình trạng overfitting trong mô hình. Mô hình Random Forest có khả năng tổng quát hóa tốt hơn và có thể dự đoán chính xác trên dữ liệu mới hơn so với các mô hình hồi quy khác.
  - Đối với phương pháp Decision Tree Regressor, để giảm overfitting có thể áp dụng một số kỹ thuật như sau:
    - Cắt tỉa cây: Kỹ thuật cắt tỉa cây là phương pháp loại bỏ các nhánh không quan trọng của cây. Nó giúp giảm độ sâu của cây và tránh việc cây quá phức tạp, dẫn đến tình trạng overfitting.
    - Sử dụng giới hạn độ sâu cây: Giới hạn độ sâu cây là một cách hiệu quả để giảm overfitting. Giới hạn độ sâu cây giúp hạn chế số lượng các quyết định được thực hiện bởi cây quyết định, giảm khả năng mô hình học quá nhiều từ dữ liệu huấn luyện và không thể tổng quát hóa tốt cho dữ liệu mới.
    - Tăng cường dữ liệu: Tăng cường dữ liệu là một phương pháp giảm overfitting bằng cách tạo ra thêm dữ liệu mới từ các bản ghi hiện có. Phương pháp này giúp tăng độ phong phú và đa dạng của dữ liệu huấn luyện, từ đó giảm thiểu sự phụ thuộc vào dữ liệu huấn luyện và giảm khả năng overfitting.
    - Sử dụng regularization: Kỹ thuật regularization là một phương pháp giúp giảm overfitting bằng cách giới hạn giá trị của các tham số mô hình. Regularization giúp mô hình trở nên đơn giản hơn và ít có khả năng bị overfitting.

## 4. Để cải thiện chất lượng mô hình:
  - Thu thập thêm dữ liệu: Một lượng lớn dữ liệu huấn luyện có thể giúp mô hình học được nhiều thông tin hơn, cải thiện khả năng tổng quát hóa và giảm thiểu overfitting.
  - Chọn đặc trưng tốt: Chọn các đặc trưng quan trọng và loại bỏ những đặc trưng không quan trọng, giúp mô hình tập trung vào các đặc trưng cần thiết để dự đoán đầu ra.
  - Tiền xử lý dữ liệu: Loại bỏ các dữ liệu nhiễu, xử lý các giá trị khuyết, chuẩn hóa dữ liệu, tạo các đặc trưng mới, giúp mô hình học được mối quan hệ giữa các đặc trưng và đầu ra chính xác hơn.
  - Sử dụng mô hình phù hợp: Chọn mô hình phù hợp với bài toán và kiểu dữ liệu của bạn, ví dụ như sử dụng các mô hình có khả năng xử lý dữ liệu dạng chuỗi cho bài toán dự đoán văn bản.
  - Chọn các siêu tham số tốt: Các mô hình học máy có các siêu tham số như số lượng cây trong mô hình Random Forest, độ sâu của cây trong Decision Tree Regressor. Tinh chỉnh các siêu tham số này giúp cải thiện chất lượng của mô hình.
  - Ensemble Learning: Ensemble Learning là phương pháp kết hợp nhiều mô hình dự đoán khác nhau để tạo ra một dự đoán tốt hơn. Việc sử dụng mô hình Random Forest hoặc Gradient Boosting là hai ví dụ điển hình cho phương pháp này.
  - Kiểm định chéo (Cross-validation): Kiểm định chéo giúp đánh giá chính xác khả năng tổng quát hóa của mô hình, tránh overfitting và underfitting.
  - Regularization: Regularization là một phương pháp để giảm overfitting bằng cách thêm các giá trị phạt vào các hệ số của mô hình. L1 regularization (Lasso) và L2 regularization (Ridge) là hai ví dụ điển hình cho phương pháp này.
  - Tăng cường dữ liệu (Data augmentation): Tăng cường dữ liệu bằng cách thêm dữ liệu mới hoặc biến đổi dữ liệu cũ giúp mô hình học được nhiều mẫu dữ
